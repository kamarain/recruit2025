<!--This is website to advertice our open doctoral reseracher position. It should look nice and airy, modern, with Open Sans font. It should work nicely with computer browser as well as with mobile phone. The background should be plain white and text should be normal black.

The title of the page should be "Call for Doctoral Students" and this title should be shown at the top of the page. 

The page should be centered in the browser window and the maximum width of the page should be 800 pixels. The page should have 20 pixels of padding on all sides. The text should be centered in the page. The font size of the title should be 28 pixels and the font size of the name should be 20 pixels. The font size of the rest of the text should be 16 pixels.

The page should have a nice background color. The color should be white. The text color should be black.

-->

<!DOCTYPE html>
<html>

<head>
    <title>Call for Phd students and postdocs</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <style>
        body {
            background-color: white;
            color: black;
            font-family: 'Open Sans', sans-serif;
            font-size: 16px;
            margin: 0;
            padding: 20px;
            text-align: justify;
            max-width: 700px !important;
            margin: 0 auto;

        }

        h1 {
            font-size: 36px;
            text-align: center;
            margin-bottom: 30px;
        }

        h2 {
            font-size: 24px;
            margin-top: 40px;
            margin-bottom: 20px;
        }

        h3 {
            font-size: 20px;
            margin-top: 30px;
            margin-bottom: 20px;
        }

        a {
            color: #0072C6;
            text-decoration: none;
        }

        a:visited {
            color: #0072C6; 
        }

        .container {
            max-width: 700px !important;
            margin: 0 auto;
        }

        figure {
            display: block;
        }

        .logo-container {
            max-width: 100%;
            margin: 0 auto;
        }
    </style>
    
</head>
<!-- p {
            max-width: 600px;
            max-width: 600px;

        } -->


<body>
    <h1>Call for Doctoral Students and Postdoctoral Researchers</h1>

    <div style="display: flex; justify-content: center; align-items: center; margin-top: 10px; margin-bottom: 30px;">
<!--        <figure style="display: inline-block;">
          <a href="https://www.aalto.fi/en" rel="some text"> <img src="assets/AaltoLogo.png" alt="AaltoLogo" style="max-width: 90%;"> </a>
        </figure> -->
      
        <figure style="display: inline-block;">
          <a href="https://www.tuni.fi/en" rel="some text"> <img src="assets/TampereLogo.png" alt="TampereLogo" style="max-width: 90%;"> </a>
        </figure>
      </div>

    <!--<figure style="width: 95%; margin: 20px auto;">
    -->

    <p>
        We are seeking new PhD students and postdocs to our computer vision and machine learning research teams in Tampere in Finland.
    </p>
    <p>
        The positions will offer excellent opportunities to work in a team of professionals responsible for developing
        cutting edge computer vision and machine learning technology, and allows you to learn many aspects from
        fundamental research problems to concrete applications.
    </p>


    <h2>Applicant</h2>

    <p>
        We welcome applications with any research focus related to computer vision and machine learning. In addition, we
        are especially seeking candidates with the following research focus:
    </p>
    <ul>
        <li>Large-scale multi modal learning (e.g. audio, visual, and language)</li>
        <li>Deep learning based 3D scene reconstruction</li>
        <li>Augmented reality for games and mobile applications (Android and/or iOS)</li>
    </ul>
    <p>
        Ideal candidate has a strong programming and mathematics background. Experience in (or strong will to learn)
        programming with Python or C++/Java are considered as advantages.
    </p>


    <h2>Team and research</h2>

    <p>
        The doctoral candidates will be supervised by <a href="http://esa.rahtu.fi" rel="some text">Professor Esa
            Rahtu</a> (Tampere University) and <a href="https://users.aalto.fi/~kannalj1/" rel="some text">Associate
            Professor Juho Kannala</a> (Aalto University). We work broadly in the fields of computer vision and machine
        learning. We are pursuing research problems in geometric computer vision (including topics such as visual SLAM,
        visual-inertial odometry, and 3D scene reconstruction), in semantic computer vision (including topics such as
        image-based localization, object detection and recognition, and deep learning), and large-scale multi modal
        learning (including audio-visual sound source separation, visually guided sound generation, and audio-visual
        synchronization). More information of our research is available on our web pages linked below. (You can follow
        the links by clicking the images.)
    </p>

    <div style="display: flex; justify-content: center; margin-top: 10px; margin-bottom: 30px;">

      <figure style="display: inline-block;">
            <a href="https://www.gokhanalcan.com/" rel="some text"> <img height=150 src="assets/gokhan.png" alt="Gokhan"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://www.gokhanalcan.com/" rel="some text"> Gokhan Alcan </a></figcaption>
        </figure>

      <figure style="display: inline-block;">
            <a href="https://sites.google.com/view/iosifidis" rel="some text"> <img height=150 src="assets/alexandros.png" alt="Alexandros"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://sites.google.com/view/iosifidis" rel="some text"> Alexandros Iosifidis </a></figcaption>
        </figure>

      <figure style="display: inline-block;">
            <a href="https://www.tuni.fi/en/people/reza-ghabcheloo" rel="some text"> <img height=150 src="assets/reza.png" alt="Reza"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://www.tuni.fi/en/people/reza-ghabcheloo" rel="some text"> Reza Ghabcheloo </a></figcaption>
        </figure>

      </div>
      
    <div style="display: flex; justify-content: center; margin-top: 10px; margin-bottom: 30px;">
      
        <figure style="display: inline-block;">
            <a href="https://www.tuni.fi/en/people/juho-kanniainen"> <img height=150 src="assets/juho_tuni.png" alt="Juho"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://www.tuni.fi/en/people/juho-kanniainen" rel="some text"> Juho Kanniainen </a></figcaption>
        </figure>


      <figure style="display: inline-block;">
            <a href="https://webpages.tuni.fi/vision/public_pages/JoniKamarainen/" rel="some text"> <img height=150 src="assets/joni.jpg" alt="Joni"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://webpages.tuni.fi/vision/public_pages/JoniKamarainen/" rel="some text"> Joni Kamarainen </a></figcaption>
        </figure>

        <figure style="display: inline-block;">
            <a href="https://www.tuni.fi/en/people/roel-pieters" rel="some text"> <img height=150 src="assets/roel.png" alt="Roel"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="https://www.tuni.fi/en/people/roel-pieters" rel="some text"> Roel Pieters </a></figcaption>
        </figure>

    </div>

    <div style="display: flex; justify-content: center; margin-top: 10px; margin-bottom: 30px;">

	
        <figure style="display: inline-block;">
            <a href="http://esa.rahtu.fi" rel="some text"> <img height=150 src="assets/esa.png" alt="Esa"> </a>
            <figcaption style="font-size: 18px; font-style: light; width: 100%; justify-content: center; "><a href="http://esa.rahtu.fi" rel="some text"> Esa Rahtu </a></figcaption>
        </figure>

    </div>

    <h3>Spectral color constancy</h3>
    <p>
      <b>Note:</b> This position is located at ams OSRAM Research Center, Jena, Germany
    </p>
    <p>
      Color constancy makes sure that colors look the same in different illuminations. In digital cameras, color constancy - or Auto White Balance (AWB) - is done by by estimating the color of illuminant and by normalizing the sensor values like they would have been captured under a white light source. However, the estimation often fails and leads to poor results. Very recently, we have developed a method based on spectral sensing which is more accurate representation of color than RGB. Understanding spectral color constancy is highly important for camera manufacturers and for the manufacturers of spectral sensors. Our approach is described in this <a href="https://link.springer.com/article/10.1007/s11263-023-01867-x">paper</a> or alternatively you can watch the video at the <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0506.html">BMVC web site</a>.
    </p>

    <!--
    <div style="display: flex; justify-content: center; margin-top: 50px; margin-bottom: 50px;">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/8V_EGJrPHeA" frameborder="0" gesture="media"
            allow="encrypted-media" allowfullscreen></iframe>
    </div>
    -->
    
        <figure style="width: 95%; margin: 20px auto;">
        <img src="assets/single_pixel_color_constancy_teaser.png" alt="single_pixel_color_constancy_teaser.png"
            style="width: 100%; display: block; margin-bottom: 10px; margin-top: 10px;">
        <figcaption style="font-size: 14px; font-style: light; width: 100%; justify-content: center; ">Real spectral dataset examples. Solid black line denotes the light source power spectrum (ground truth) and the dashed is the measured average reflected spectrum. Gray dotted lines are the 14 spectral channels used in our experiments. For each image the three most important channels found by leave-one-out are colored with their corresponding wavelength and the most important denoted by a asterisk (percentage numbers denote the increase in angular error if this is removed compared to the second most important channel).</figcaption>
    </figure>

    <h3>Image based localisation and SLAM</h3>

    <p>
        We have investigated machine learning based approaches for visual localization and SLAM systems. For instance,
        we have developed a CNN-based <a href="https://arxiv.org/abs/1808.04999">scene coordinate regression
            method</a> for image-based localization. The new model can be trained without careful initialization, and
        the system achieves accurate results. Another example is a method for scalable and fully 3D magnetic field SLAM
        using local anomalies in the magnetic field as a source of position information.
    </p>

    <h3>Visually guided audio generation</h3>
    <p>
        The generation of visually relevant, high-quality sounds is a longstanding challenge of deep learning. Solving
        this challenge would allow sound designers to spend less time searching large foley databases for the sound that
        is relevant to a specific video scene. We approach the visually guided sound generation by shrinking a training
        dataset of audio spectrograms to a set of representative vectors aka. a codebook. Similar to word tokens in
        language modeling, these codebook vectors can be used by a transformer to sample a representation that can be
        easily decoded into a spectrogram and subsequently to audio stream. The video explains our
        approach presented in this <a href="https://arxiv.org/abs/2110.08791">paper</a>
    </p>

    <div style="display: flex; justify-content: center; margin-top: 50px; margin-bottom: 50px;">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/Bucb3nAa398" frameborder="0" gesture="media"
            allow="encrypted-media" allowfullscreen></iframe>
    </div>

    <h3>Audio-visual synchronisation</h3>

    <p>
        Audio-visual synchronisation is the task of determining the temporal offset between the audio (sound) and visual
        (image) streams in a video. In recent literature, this task has been explored by exploiting strong correlations
        between the audio and visual streams, e.g. in human speech and playing instruments, to provide a training signal
        for deep neural networks. Rather than focusing on a specialised domain, such as human speech, we explore AV
        synchronisation for videos of general thematic content, e.g. daily videos and live sports. For more information,
        take a look at our <a href="https://arxiv.org/abs/2210.07055">paper</a>
    </p>

    <!--
    <div style="display: flex; justify-content: center;">
        <img src="assets/sparse_selector_teaser.png" alt="sparse_selector_teaser.png"
            style="max-width: 80%; margin-top: 20px; margin-bottom: 20px;">
    </div> -->

    <figure style="width: 95%; margin: 20px auto;">
        <img src="assets/sparse_selector_teaser.png" alt="sparse_selector_teaser.png"
            style="width: 100%; display: block; margin-bottom: 10px; margin-top: 10px;">
        <figcaption style="font-size: 14px; font-style: light; width: 100%; justify-content: center; ">Audio-visual
            synchronisation requires a model to relate changes in the visual and audio streams. Prior work focused
            primarily on the synchronisation of talking head videos (left). In contrast, open-domain videos often have a
            small visual indication, i.e. sparse in space (right). Moreover, cues may be intermittent and scattered,
            i.e. sparse across time, e.g. a lion only roars once during a video clip.</figcaption>
    </figure>

    <!-- <p>
        Audio-visual synchronisation requires a model to relate changes in the visual and audio streams. Prior work
        focused primarily on the synchronisation of talking head videos (left). In contrast, open-domain videos often
        have a small visual indication, i.e. sparse in space (right). Moreover, cues may be intermittent and scattered,
        i.e. sparse across time, e.g. a lion only roars once during a video clip.
    </p> -->


    <h2>Host institutions</h2>

    <p>
        <a href="https://www.tuni.fi/en">Tampere
            University</a> is the leading university in engineering and technology in <a
            href="https://en.wikipedia.org/wiki/Finland">Finland</a>.
    </p>

<!--    <p>
        The Computer Science Department at Aalto provides world-class research and education in modern computer science
        to foster future science, engineering and society. The work combines fundamental research with innovative
        applications. The department is routinely ranked among the top 10 CS departments in Europe and in the top 100
        globally.
    </p> -->

    <p>
        The Signal Processing at Tampere University has 170 members of which 30-40% are of foreign origin. The
        department has held the prestiguous status of a Center of Excellence in Research (CoE) elected by the Finnish
        Academy of Sciences. Core areas of research include image, video and audio signal processing and analysis as
        well as machine learning related topics. The institute is also part of the European Laboratory for Learning and Intelligent Systems (<a href="https://ellis.eu/">ELLIS</a>) that provides a strong network of the best European researchers.
    </p>


    <h2>Compensation</h2>

    <p>
        The starting salary of a PhD student is ca. 2400 EUR per month and it will increase during the studies
        depending on the progress (up to 3100 EUR per month). The salary for a postdoctoral researcher starts typically from 3500  EUR per month, and increases based on experience.
    </p>

    <p>
        In addition to the salary, the contract includes occupational healthcare benefits, and Finland has a
        comprehensive social security system. The positions are located at Aalto University and Tampere University.
    </p>


    <h2>How to apply</h2>

    <p>
        The applications are submitted to the application portals of the corresponding universities. We highly
        recommend you to apply through both portals, even if you have a clear preference on which university you
        prefer, this can be decided later in any case.
    </p>
    <p>
        The links to the application portals:
    <ul>
        <li>Tampere University (phd): <a href="https://www.tuni.fi/en/about-us/careers-tampere-universities">link</a></li>
        <li>Tampere University (postdoc): <a href="https://www.tuni.fi/en/about-us/careers-tampere-universities">link</a></li>
    </ul>
    </p>



    <h2>Questions?</h2>
    <p>
      If you have any questions regarding the positions or the applications, please contact the listed PIs.
    </p>


</body>

</html>
